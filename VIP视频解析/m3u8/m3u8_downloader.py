import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
import os
from urllib.parse import urlparse
import subprocess
import shutil
from tenacity import retry, stop_after_attempt, wait_fixed, RetryError
import re

from PySide6.QtCore import QObject, Signal

from enum import Enum

class DownloadState(Enum):
    DoneAll = 1
    Lost = 2

class M3u8Downloader(QObject):
    # å®šä¹‰ä¸€ä¸ªä¿¡å·
    info_signal = Signal(str)
    progress_signal = Signal(dict)
    avg_speed_signal = Signal(float)
    download_state_signal = Signal(tuple)
    got_video_duration_signal = Signal(float, str)
    finished = Signal()

    maxWorkers = 5

    def __init__(self, inputString, ban_ads=False, dir_path='D:\\', head_time='0:0', tail_time='999999:0'):
        super().__init__()

        # Split the content into lines
        lines = inputString.strip().splitlines()

        # Initialize an array to store the extracted data
        infos = []
        for line in lines:
            info = {}
            parts = line.split('$')

            if len(parts) == 1 :
                info['name'] = 'æœªå‘½å'
                info['url'] = parts[0]
            elif len(parts) >= 2:
                info['name'] = parts[0]
                info['url'] = parts[1]
            else:
                continue
            info['lines'] = None
            infos.append(info)
        
        self.m3u8_infos = infos
        self.baned_ads = ban_ads
        self.dir_path = dir_path
        self.head_time = re.sub(r"[-ï¼š _]", ":", head_time) or '0:0'
        self.tail_time = re.sub(r"[-ï¼š _]", ":", tail_time) or '999999:0'
        self.baned_head_tail = not (head_time=='0:0'and tail_time=='999999:0')

        self.executor = ThreadPoolExecutor(max_workers=self.maxWorkers)
        self.futures = []  # ç”¨äºå­˜å‚¨ä»»åŠ¡çš„å¼•ç”¨
        self._is_cancelled = False  # ç”¨äºæ§åˆ¶ä»»åŠ¡æ˜¯å¦è¢«å–æ¶ˆ
        self._is_paused = False  # æ§åˆ¶æ˜¯å¦æš‚åœ

    def cancel(self):
        self._is_cancelled = True
        self._is_paused = False
        self.executor.shutdown(wait=False)  # éé˜»å¡åœ°å…³é—­çº¿ç¨‹æ± 

    def pause(self):
        self._is_paused = True
        self.info_signal.emit("ä¸‹è½½å·²æš‚åœã€‚")

    def resume(self):
        self._is_paused = False
        self.info_signal.emit("ä¸‹è½½å·²æ¢å¤ã€‚")

    def _bake_correct_url(self, m3u8_url, part_url):
        if 'https:' in part_url or 'http:' in part_url:
            return part_url
        else:
            # æ„å»ºæœ€åä¸€ä¸ªæ–œæ å‰çš„éƒ¨åˆ†
            url_without_last_part = m3u8_url
            last_slash_index = m3u8_url.rfind('/')
            if last_slash_index!= -1:
                url_without_last_part = m3u8_url[:last_slash_index] + '/'

            str1 = url_without_last_part
            str2 = part_url# if part_url[0] == '/' else '/'+part_url
            common_part = ""
            for i in range(len(str1)):
                if str1[i:] == str2[:len(str1)-i]:
                    common_part = str1[i:]
                    break
            correct_url = str1[:len(str1)-len(common_part)] + str2
            return correct_url

    def get_ts_lines(self, url):
        # print(f'fetched url: {url}')
        # Fetch the m3u8 content from the provided URL
        try:
            # å‘é€HTTP GETè¯·æ±‚è·å–æ–‡ä»¶å†…å®¹
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36 Edg/130.0.0.0'}
            response = requests.get(url, headers=headers)
            response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ

            m3u8_content = response.text

            # Split the content by lines
            lines = m3u8_content.splitlines()

            # éå†æ‰€æœ‰è¡Œ
            for i in range(len(lines)):
                # å°†urlä¿®æ”¹æˆå¸¦åŸŸåçš„é“¾æ¥
                good_lines = []
                # éå†linesæ•°ç»„
                i = 0
                while i < len(lines):
                    # å¦‚æœå…ƒç´ æ˜¯#EXTINFå¼€å¤´çš„ï¼Œæ„å‘³ç€æˆ‘ä»¬æ‰¾åˆ°äº†ä¸€ç»„
                    if lines[i].startswith("#EXTINF"):
                        ts_url = lines[i + 1]  # ts æ–‡ä»¶åº”è¯¥ç´§è·Ÿåœ¨ #EXTINF ä¹‹å
                        ts_url = self._bake_correct_url(url, ts_url)
                        good_lines.append(lines[i])
                        good_lines.append(ts_url)
                        # è·³è¿‡å·²å¤„ç†çš„ä¸¤è¡Œ
                        i += 2
                    # å¦‚æœå½“å‰è¡Œä»¥ "#EXT-X-STREAM-INF:" å¼€å¤´
                    elif lines[i].startswith("#EXT-X-STREAM-INF:"):
                        # æ£€æŸ¥ä¸‹ä¸€è¡Œæ˜¯å¦å­˜åœ¨å¹¶æå–å‡ºæ¥
                        if i + 1 < len(lines):
                            stream_url = lines[i + 1]
                            stream_url = self._bake_correct_url(url, stream_url)
                            return self.get_ts_lines(stream_url)
                    else:
                        # å¦‚æœå½“å‰å…ƒç´ ä¸æ˜¯#EXTINFå¼€å¤´çš„ï¼Œå°±ç›´æ¥åŠ å…¥ç»“æœä¸­
                        good_lines.append(lines[i])
                        i += 1
                return good_lines

        except requests.Timeout:
            self.info_signal.emit("âŒä¸‹è½½m3u8æ–‡ä»¶è¶…æ—¶ï¼")
            return []
        except requests.ConnectionError:
            self.info_signal.emit(f"âŒä¸‹è½½m3u8æ–‡ä»¶è¿æ¥é”™è¯¯ï¼")
            return []
        except requests.HTTPError as e:
            self.info_signal.emit(f"âŒä¸‹è½½m3u8æ–‡ä»¶æ—¶æœåŠ¡å™¨è¿”å›é”™è¯¯ï¼š{e.response.status_code}")
            return []
        except requests.RequestException as e:
            print(url)
            self.info_signal.emit(f"âŒä¸‹è½½m3u8æ–‡ä»¶æ—¶å‡ºç°æœªçŸ¥é”™è¯¯:{e}")
            return []

    def get_trim_head_tail_lines(self, lines, head, tail):
        if not self.baned_head_tail:
            return lines
        
        # åˆ†å‰²æ—¶é—´ä¸ºåˆ†é’Ÿå’Œç§’
        minutes1, seconds1 = map(int, head.split(":"))
        minutes2, seconds2 = map(int, tail.split(":"))
        # è®¡ç®—æ€»ç§’æ•°
        head_seconds = minutes1 * 60 + seconds1
        tail_seconds = minutes2 * 60 + seconds2

        # ç”¨æ¥ä¿å­˜å¤„ç†åçš„lines
        result_lines = []
        # å¤„ç†ç»„çš„è®¡æ•°
        total_duration = 0.0
        # éå†linesæ—¶çš„æŒ‡é’ˆ
        i = 0
        # éå†linesæ•°ç»„
        while i < len(lines):
            # å¦‚æœå…ƒç´ æ˜¯#EXTINFå¼€å¤´çš„ï¼Œæ„å‘³ç€æˆ‘ä»¬æ‰¾åˆ°äº†ä¸€ç»„
            if lines[i].startswith("#EXTINF"):
                # æå–#EXTINFåçš„æ•°å­—
                ext_inf_line = lines[i]
                ts_file = lines[i + 1]  # ts æ–‡ä»¶åº”è¯¥ç´§è·Ÿåœ¨ #EXTINF ä¹‹å

                # æå–æ—¶é•¿å¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                duration = float(ext_inf_line.split(":")[1].strip(","))

                if head_seconds < total_duration + duration < tail_seconds:
                    result_lines.append(ext_inf_line)
                    result_lines.append(ts_file)

                # æ›´æ–°æ€»æ—¶é•¿
                total_duration += duration

                # è·³è¿‡å·²å¤„ç†çš„ä¸¤è¡Œ
                i += 2
            else:
                # å¦‚æœå½“å‰å…ƒç´ ä¸æ˜¯#EXTINFå¼€å¤´çš„ï¼Œå°±ç›´æ¥åŠ å…¥ç»“æœä¸­
                result_lines.append(lines[i])
                i += 1

        # è¾“å‡ºæœ€ç»ˆçš„ç»“æœ
        return result_lines

    def get_ignore_ads_lines(self, lines):
        if not self.baned_ads:
            return lines
        # Initialize a variable to keep track if we are inside the block to remove
        inside_discontinuity_block = False
        result_lines = []
        for line in lines:
            if "#EXT-X-DISCONTINUITY" in line:
                inside_discontinuity_block = not inside_discontinuity_block  # Toggle block state
                continue  # Skip the line
            if "#EXT-X-KEY:METHOD=NONE" in line:
                continue  # Skip this line
            if not inside_discontinuity_block:
                result_lines.append(line)
        return result_lines

    def get_video_duration(self, url):
        lines = self.get_ts_lines(url)

        # æ·»åŠ è¿™è¡Œå¾ˆä¸å¥½ï¼Œä½†æ˜¯ä¸ºäº†é˜²æ­¢é‡å¤è¯·æ±‚ä¸æ”¹åŸæ¥ä»£ç å°±åŠ äº†
        for info in self.m3u8_infos:
            if url == info['url']:
                info['lines'] = lines
                break

        if lines is None or len(lines) == 0:
            return

        total_duration = 0.0
        # éå†linesæ—¶çš„æŒ‡é’ˆ
        i = 0
        # éå†linesæ•°ç»„
        while i < len(lines):
            # å¦‚æœå…ƒç´ æ˜¯#EXTINFå¼€å¤´çš„ï¼Œæ„å‘³ç€æˆ‘ä»¬æ‰¾åˆ°äº†ä¸€ç»„
            if lines[i].startswith("#EXTINF"):
                # æå–#EXTINFåçš„æ•°å­—
                ext_inf_line = lines[i]
                ts_file = lines[i + 1]  # ts æ–‡ä»¶åº”è¯¥ç´§è·Ÿåœ¨ #EXTINF ä¹‹å
                # æå–æ—¶é•¿å¹¶è½¬æ¢ä¸ºæµ®ç‚¹æ•°
                duration = float(ext_inf_line.split(":")[1].strip(","))
                # æ›´æ–°æ€»æ—¶é•¿
                total_duration += duration
                # è·³è¿‡å·²å¤„ç†çš„ä¸¤è¡Œ
                i += 2
            else:
                # å¦‚æœå½“å‰å…ƒç´ ä¸æ˜¯#EXTINFå¼€å¤´çš„ï¼Œè·³è¿‡
                i += 1

        self.got_video_duration_signal.emit(total_duration, url)

    # å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œè´Ÿè´£ä¸‹è½½URLå¹¶ä¿å­˜æ–‡ä»¶
    @retry(stop=stop_after_attempt(8), wait=wait_fixed(2))  # å°è¯•8æ¬¡ï¼Œæ¯æ¬¡é—´éš”2ç§’
    def download_file(self, url, index, download_dir):
        # æ–‡ä»¶åä¸ºç´¢å¼•å·
        file_name = os.path.join(download_dir, str(index) + '.ts')
        dir = os.path.basename(download_dir)

        if os.path.exists(file_name):
            self.info_signal.emit(f'ğŸ˜€ï¸{index}.ts å·²å­˜åœ¨')
            return 1 #1å­—èŠ‚ï¼Œè¡¨ç¤ºå·²ä¸‹è½½

        try:
            # å‘é€HTTP GETè¯·æ±‚è·å–æ–‡ä»¶å†…å®¹
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36 Edg/130.0.0.0'}
            response = requests.get(url, timeout=5, headers=headers)
            response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
            # å°†æ–‡ä»¶å†…å®¹ä¿å­˜åˆ°æœ¬åœ°
            with open(file_name, "wb") as file:
                file.write(response.content)
                self.info_signal.emit(f"ğŸ˜€ä¸‹è½½ {dir}/{index}.ts æˆåŠŸï¼")
            return len(response.content)

        except requests.Timeout:
            self.info_signal.emit(f"âš ä¸‹è½½ {dir}/{index}.ts æ—¶è¶…æ—¶ï¼Œ2ç§’åé‡è¯•ï¼")
            raise  # æŠ›å‡ºå¼‚å¸¸ä»¥è§¦å‘é‡è¯•

        except requests.ConnectionError:
            self.info_signal.emit(f"âš ä¸‹è½½ {dir}/{index}.ts æ—¶è¿æ¥é”™è¯¯ï¼Œ2ç§’åé‡è¯•ï¼")
            raise  # æŠ›å‡ºå¼‚å¸¸ä»¥è§¦å‘é‡è¯•

        except requests.HTTPError as e:
            self.info_signal.emit(f"âŒä¸‹è½½ {dir}/{index}.ts æ—¶æœåŠ¡å™¨è¿”å›é”™è¯¯ï¼š{e.response.status_code}ï¼Œä¸å†é‡è¯•ã€‚")
            return False  # ä¸é‡è¯•

        except requests.RequestException:
            self.info_signal.emit(f"âš ä¸‹è½½ {dir}/{index}.ts æ—¶å‡ºç°æœªçŸ¥é”™è¯¯ï¼Œ2ç§’åé‡è¯•ï¼")
            raise  # æŠ›å‡ºå¼‚å¸¸ä»¥è§¦å‘é‡è¯•

    def handle_download(self, url, index, download_dir):
        if self._is_cancelled:
            return 0
        else:
            while self._is_paused:  # å¦‚æœè¢«æš‚åœï¼Œåˆ™ç­‰å¾…
                time.sleep(0.1)  # ç¡®ä¿ä¸ä¼šå ç”¨ CPU èµ„æº

            try:
                return self.download_file(url, index, download_dir)
            except RetryError:
                # print(f"âŒä¸‹è½½ {index}.ts é‡è¯•æ¬¡æ•°å·²ç”¨å®Œï¼Œä¸‹è½½å¤±è´¥ï¼")  # å½“é‡è¯•æ¬¡æ•°ç”¨å®Œæ—¶æ‰“å°
                self.info_signal.emit(f"âŒä¸‹è½½ {index}.ts é‡è¯•æ¬¡æ•°å·²ç”¨å®Œï¼Œä¸‹è½½å¤±è´¥ï¼")  # å½“é‡è¯•æ¬¡æ•°ç”¨å®Œæ—¶æ‰“å°
                return 0

    def download_ts_files(self):

        for urls, m3u8_info in self.ts_urls_generater():
            if len(urls) == 0:
                self.finished.emit()
                return

            m3u8_url = m3u8_info['url']
            download_dir = os.path.join(self.dir_path, m3u8_info["name"])

            total_count = len(urls)
            completed_count = 0
            self.futures = []

            downloaded_size = 0
            start_time = time.time()

            self.info_signal.emit(f'\n\nâ€”â€”â€”â€”å‡†å¤‡ä¸‹è½½ã€Š{m3u8_info["name"]}ã€‹è§†é¢‘åˆ‡ç‰‡')

            while self._is_paused:
                time.sleep(0.1)

            if self._is_cancelled:
                self.info_signal.emit("ä¸‹è½½å·²è¢«å–æ¶ˆã€‚")
                self.finished.emit()
                return

            # ä¸ºæ¯ä¸ªURLåˆ†é…ä»»åŠ¡
            for index, url in enumerate(urls):
                future = self.executor.submit(self.handle_download, url, index, download_dir)
                self.futures.append(future)

            # ä½¿ç”¨ as_completed æ¥è·Ÿè¸ªä»»åŠ¡å®Œæˆæƒ…å†µ
            for future in as_completed(self.futures):
                
                if self._is_cancelled:
                    self.info_signal.emit("ä¸‹è½½å·²è¢«å–æ¶ˆã€‚")
                    self.finished.emit()
                    return

                data_size = future.result()
                if data_size > 0:
                    completed_count += 1

                    # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
                    progress = int((completed_count / total_count) * 100)
                    ext = {'value': progress, 'total': total_count, 'current': completed_count}
                    self.progress_signal.emit(ext)  # å‘å°„è¿›åº¦ä¿¡å·

                    # è®¡ç®—ä¸‹è½½é€Ÿåº¦
                    downloaded_size += data_size
                    if completed_count%self.maxWorkers==0: # æ¯nä¸ªåˆ‡ç‰‡è®¡ç®—å¹³å‡é€Ÿåº¦
                        end_time = time.time()
                        if end_time != start_time:
                            speed_in_mbps = (downloaded_size*8/(1024 * 1024)) / (end_time - start_time)  # MBæ¯ç§’
                            self.avg_speed_signal.emit(speed_in_mbps)
                            # print(f'å¹³å‡ä¸‹è½½é€Ÿåº¦: {speed_in_mbps:.2f} Mb/S')
                            downloaded_size = 0
                            start_time = time.time()

            if not self._is_cancelled:
                if completed_count < total_count:
                    self.download_state_signal.emit((DownloadState.Lost, download_dir))
                else:
                    # æ­¤å¤„çš„ä»£ç åœ¨ä»»åŠ¡å…¨éƒ¨å®Œæˆåæ‰ä¼šç»§ç»­æ‰§è¡Œ
                    self.process_ffmpeg(download_dir)

        # å…¨éƒ¨m3u8é“¾æ¥ä¸‹è½½å®Œå
        self.finished.emit()
        self.download_state_signal.emit((DownloadState.DoneAll, None))
        self.info_signal.emit('å…¨éƒ¨ä¸‹è½½å®Œæˆã€‚')

    def ts_urls_generater(self):
        for m3u8_info in self.m3u8_infos:
            lines = m3u8_info['lines'] or self.get_ts_lines(m3u8_info['url'])
            if len(lines) > 0:
                trim_head_tail_lines = self.get_trim_head_tail_lines(lines, self.head_time, self.tail_time)
                ignore_ads_lines = self.get_ignore_ads_lines(trim_head_tail_lines)

                save_path = os.path.join(self.dir_path, m3u8_info["name"])
                os.makedirs(save_path, exist_ok=True)

                self.save_m3u8_file(ignore_ads_lines, save_path)
                self.download_m3u8_key(m3u8_info, ignore_ads_lines, save_path)
                ts_urls = self.get_ts_urls(ignore_ads_lines)

                yield ts_urls, m3u8_info  # æ¯æ¬¡è¿”å›ä¸€ä¸ª m3u8_info å’Œå¯¹åº”çš„ urls
            else:
                yield [], {}

    def save_m3u8_file(self, lines, download_dir):
        result_lines = []
        # éå†linesæ—¶çš„æŒ‡é’ˆ
        i = 0
        f = 0
        # éå†linesæ•°ç»„
        while i < len(lines):
            # å¦‚æœå…ƒç´ æ˜¯#EXTINFå¼€å¤´çš„ï¼Œæ„å‘³ç€æˆ‘ä»¬æ‰¾åˆ°äº†ä¸€ç»„
            if lines[i].startswith("#EXTINF"):
                result_lines.append(lines[i])
                result_lines.append(f"{f}.ts")
                i = i + 2
                f = f + 1
            else:
                result_lines.append(lines[i])
                i = i + 1

        # Join the filtered lines
        filtered_m3u8_content = "\n".join(result_lines)
        # Save the result to a local file
        output_file_path = os.path.join(download_dir, 'ts.m3u8')
        with open(output_file_path, "w") as file:
            file.write(filtered_m3u8_content)

    def download_m3u8_key(self, m3u8_info, lines, download_dir):
        secret_key_name = None
        # éå†linesæ—¶çš„æŒ‡é’ˆ
        i = 0
        # éå†linesæ•°ç»„
        while i < len(lines):
            if lines[i].startswith('#EXT-X-KEY'):
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå– URI
                uri_pattern = r'URI="([^"]+)"'
                match = re.search(uri_pattern, lines[i])
                secret_key_name = match.group(1) if match else None
                break
            i = i + 1

        # å¦‚æœæœ‰åŠ å¯†æ–‡ä»¶åˆ™ä¸‹è½½
        if secret_key_name:
            m3u8_url = m3u8_info['url']
            # æŸ¥æ‰¾æœ€åä¸€ä¸ª '/' çš„ä½ç½®
            last_slash_index = m3u8_url.rfind('/')
            # æˆªå–æœ€åä¸€ä¸ª '/' ä¹‹å‰çš„å­—ç¬¦ä¸²
            part_url = m3u8_url[:last_slash_index + 1]
            secret_key_url = part_url + '/' + secret_key_name

            try:
                response = requests.get(secret_key_url)
                response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ
                file_name = os.path.join(download_dir, secret_key_name)
                with open(file_name, "wb") as file:
                    file.write(response.content)

            except requests.RequestException:
                # print("ä¸‹è½½å¯†é’¥æ–‡ä»¶å‡ºé”™ï¼ï¼")
                self.info_signal.emit("ä¸‹è½½å¯†é’¥æ–‡ä»¶å‡ºé”™ï¼ï¼")

    def get_ts_urls(self, lines):
        ts_urls = []
        # éå†linesæ—¶çš„æŒ‡é’ˆ
        i = 0
        # éå†linesæ•°ç»„
        while i < len(lines):
            # å¦‚æœå…ƒç´ æ˜¯#EXTINFå¼€å¤´çš„ï¼Œæ„å‘³ç€æˆ‘ä»¬æ‰¾åˆ°äº†ä¸€ç»„
            if lines[i].startswith("#EXTINF"):
                url = lines[i + 1]  # ts æ–‡ä»¶åº”è¯¥ç´§è·Ÿåœ¨ #EXTINF ä¹‹å
                ts_urls.append(url)
                i = i + 2
            else:
                i = i + 1
        return ts_urls

    def process_ffmpeg(self, download_dir):
        # å®šä¹‰ffmpegå‘½ä»¤çš„å‚æ•°
        m3u8_file = os.path.join(download_dir, 'ts.m3u8')  # è¾“å…¥çš„m3u8æ–‡ä»¶
        parent_dir = os.path.dirname(download_dir)
        # è·å–æœ€åä¸€ä¸ªç›®å½•åç§°
        last_dir = os.path.basename(download_dir)
        output_file = os.path.join(parent_dir, f'{last_dir}.mp4')  # è¾“å‡ºçš„mp4æ–‡ä»¶

        # åˆå¹¶å‰åˆ¤æ–­æœ‰åŒå‘½åæ–‡ä»¶
        if os.path.exists(output_file):
            output_file = os.path.join(parent_dir, f'{last_dir}_1.mp4')

        # æ„å»ºffmpegå‘½ä»¤
        command = [
            "ffmpeg",
            "-allowed_extensions", "ALL",
            "-protocol_whitelist", "file,http,crypto,tcp",
            "-i", m3u8_file,
            "-c", "copy",
            "-y", output_file
        ]

        # æ‰§è¡Œå‘½ä»¤
        try:
            # ä½¿ç”¨subprocessè¿è¡Œå‘½ä»¤ï¼Œå¹¶æ•è·è¾“å‡º
            result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
            if result.returncode == 0:
                # print(f"â€”â€”â€”â€”â€”â€”â€”â€” {output_file} æ–‡ä»¶å·²ç”Ÿæˆ â€”â€”â€”â€”â€”â€”â€”â€”")
                self.info_signal.emit(f"â€”â€”â€”â€”â€”â€”â€”â€” {output_file} æ–‡ä»¶å·²ç”Ÿæˆ")

                # åˆ é™¤æœ¬åœ°tsæ–‡ä»¶
                # ä½¿ç”¨rmtreeé€’å½’åˆ é™¤ç›®å½•åŠå…¶å†…å®¹
                shutil.rmtree(download_dir)
                # print(f'æ¸…ç†æœ¬åœ°ç›®å½• {download_dir} done.')
                self.info_signal.emit(f'æ¸…ç†æœ¬åœ°ç›®å½• {download_dir} done.')
            else:
                # æ‰‹åŠ¨è§£ç è¾“å‡ºï¼ˆå¤„ç†éASCIIå­—ç¬¦ï¼‰
                self.info_signal.emit("å‘½ä»¤è¾“å‡º:", result.stdout.decode('utf-8', errors='ignore'))
                self.info_signal.emit("å‘½ä»¤é”™è¯¯ä¿¡æ¯:", result.stderr.decode('utf-8', errors='ignore'))
        except subprocess.CalledProcessError as e:
            # å¦‚æœæ‰§è¡Œå‘½ä»¤æ—¶å‘ç”Ÿé”™è¯¯ï¼Œæ•è·å¹¶æ‰“å°é”™è¯¯ä¿¡æ¯
            self.info_signal.emit("æ‰§è¡Œå‘½ä»¤æ—¶å‘ç”Ÿé”™è¯¯:", e.stderr.decode('utf-8', errors='ignore'))